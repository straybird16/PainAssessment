{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KinematicsDataset(Dataset):\n",
    "    def __init__(self, dataframe, leave_out_subject, feature_cols, target_col, subject_col):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for leave-one-subject-out cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input DataFrame with features, subject column, and target column.\n",
    "            leave_out_subject (str): Subject to leave out for validation/testing.\n",
    "            feature_cols (list): List of feature column names.\n",
    "            target_col (str): Name of the target column (pain level, protected behavior, or both).\n",
    "            subject_col (str): Name of the subject column.\n",
    "        \"\"\"\n",
    "        # Split data into training and test sets\n",
    "        self.train_data = dataframe[dataframe[subject_col] != leave_out_subject]\n",
    "        self.test_data = dataframe[dataframe[subject_col] == leave_out_subject]\n",
    "\n",
    "        # Extract features and targets\n",
    "        self.features = self.train_data[feature_cols].values\n",
    "        self.targets = self.train_data[target_col].values\n",
    "        self.test_features = self.test_data[feature_cols].values\n",
    "        self.test_targets = self.test_data[target_col].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single sample from the training dataset.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the sample.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (feature_tensor, target_tensor)\n",
    "        \"\"\"\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return feature, target\n",
    "\n",
    "    def get_test_data(self):\n",
    "        \"\"\"\n",
    "        Get the test set for the current subject.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (test_features_tensor, test_targets_tensor)\n",
    "        \"\"\"\n",
    "        test_features = torch.tensor(self.test_features, dtype=torch.float32)\n",
    "        test_targets = torch.tensor(self.test_targets, dtype=torch.float32)\n",
    "        return test_features, test_targets\n",
    "\n",
    "# Example usage\n",
    "def prepare_dataset(dataframe, feature_cols, target_col, subject_col):\n",
    "    \"\"\"\n",
    "    Generate leave-one-subject-out splits and return datasets for each subject.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame.\n",
    "        feature_cols (list): List of feature column names.\n",
    "        target_col (str): Name of the target column (pain level).\n",
    "        subject_col (str): Name of the subject column.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with subjects as keys and corresponding datasets as values.\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    subjects = dataframe[subject_col].unique()\n",
    "    \n",
    "    for subject in subjects:\n",
    "        datasets[subject] = KinematicsDataset(dataframe, subject, feature_cols, target_col, subject_col)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Usage Example:\n",
    "# Assuming df is your DataFrame, and you want to split it.\n",
    "# df = pd.read_csv('your_data.csv')  # Load your DataFrame\n",
    "feature_columns = [f'feature_{i}' for i in range(20)]  # Adjust as per your feature column names\n",
    "target_column = 'pain_level'\n",
    "subject_column = 'subject'\n",
    "\n",
    "datasets = prepare_dataset(df, feature_columns, target_column, subject_column)\n",
    "\n",
    "# Get the dataset for a specific subject\n",
    "leave_out_subject = 'Subject_1'  # Example subject\n",
    "dataset = datasets[leave_out_subject]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "test_features, test_targets = dataset.get_test_data()\n",
    "\n",
    "# Example: Iterate through train data\n",
    "for batch_features, batch_targets in train_loader:\n",
    "    print(batch_features.shape, batch_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, dataframe, leave_out_subject, feature_cols, target_col, subject_col, window_length, step_size):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset with sliding window for leave-one-subject-out cross-validation.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input DataFrame with features, subject column, and target column.\n",
    "            leave_out_subject (str): Subject to leave out for validation/testing.\n",
    "            feature_cols (list): List of feature column names.\n",
    "            target_col (str): Name of the target column (pain level).\n",
    "            subject_col (str): Name of the subject column.\n",
    "            window_length (int): Length of each sliding window.\n",
    "            step_size (int): Step size for sliding window.\n",
    "        \"\"\"\n",
    "        self.window_length = window_length\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        self.train_data = dataframe[dataframe[subject_col] != leave_out_subject]\n",
    "        self.test_data = dataframe[dataframe[subject_col] == leave_out_subject]\n",
    "\n",
    "        # Generate sliding windows\n",
    "        self.train_windows = self._generate_windows(self.train_data, feature_cols, target_col, subject_col)\n",
    "        self.test_windows = self._generate_windows(self.test_data, feature_cols, target_col, subject_col)\n",
    "\n",
    "    def _generate_windows(self, data, feature_cols, target_col, subject_col):\n",
    "        \"\"\"\n",
    "        Generate sliding window samples using numpy stride tricks.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): Data subset for training or testing.\n",
    "            feature_cols (list): List of feature column names.\n",
    "            target_col (str): Target column name.\n",
    "            subject_col (str): Subject column name.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Features and targets for all windows.\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        subjects = data[subject_col].unique()\n",
    "\n",
    "        for subject in subjects:\n",
    "            subject_data = data[data[subject_col] == subject]\n",
    "            features = subject_data[feature_cols].values\n",
    "            targets = subject_data[target_col].values\n",
    "\n",
    "            if len(features) < self.window_length:\n",
    "                # Handle case where data is shorter than window length\n",
    "                padded_features = np.zeros((self.window_length, features.shape[1]), dtype=np.float32)\n",
    "                padded_targets = np.zeros((self.window_length,), dtype=np.float32)\n",
    "                padded_features[:len(features)] = features\n",
    "                padded_targets[:len(targets)] = targets\n",
    "\n",
    "                features_list.append(padded_features[np.newaxis, ...])  # Add new axis to match shape\n",
    "                targets_list.append(padded_targets[np.newaxis, ...])  # Add new axis to match shape\n",
    "            else:\n",
    "                # Generate sliding windows\n",
    "                feature_windows = np.lib.stride_tricks.sliding_window_view(\n",
    "                    features, (self.window_length, features.shape[1])\n",
    "                )[::self.step_size, 0, :, :]\n",
    "                target_windows = np.lib.stride_tricks.sliding_window_view(\n",
    "                    targets, self.window_length\n",
    "                )[::self.step_size, 0, :]\n",
    "\n",
    "                features_list.append(feature_windows)\n",
    "                targets_list.append(target_windows)\n",
    "\n",
    "        # Concatenate all windows\n",
    "        all_features = np.concatenate(features_list, axis=0)\n",
    "        all_targets = np.concatenate(targets_list, axis=0)\n",
    "\n",
    "        return all_features, all_targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_windows[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (feature_tensor, target_tensor)\n",
    "        \"\"\"\n",
    "        feature_window = self.train_windows[0][idx]\n",
    "        target_window = self.train_windows[1][idx]\n",
    "        return (\n",
    "            torch.tensor(feature_window, dtype=torch.float32),\n",
    "            torch.tensor(target_window, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def get_test_data(self):\n",
    "        \"\"\"\n",
    "        Get the test set for the current subject.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Test features and targets.\n",
    "        \"\"\"\n",
    "        test_features, test_targets = self.test_windows\n",
    "        return (\n",
    "            torch.tensor(test_features, dtype=torch.float32),\n",
    "            torch.tensor(test_targets, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# Example usage\n",
    "def prepare_sliding_window_dataset(dataframe, feature_cols, target_col, subject_col, window_length, step_size):\n",
    "    \"\"\"\n",
    "    Generate leave-one-subject-out sliding window datasets for each subject.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame.\n",
    "        feature_cols (list): List of feature column names.\n",
    "        target_col (str): Name of the target column.\n",
    "        subject_col (str): Name of the subject column.\n",
    "        window_length (int): Length of each sliding window.\n",
    "        step_size (int): Step size for the sliding window.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of datasets keyed by subject.\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    subjects = dataframe[subject_col].unique()\n",
    "    \n",
    "    for subject in subjects:\n",
    "        datasets[subject] = SlidingWindowDataset(\n",
    "            dataframe, subject, feature_cols, target_col, subject_col, window_length, step_size\n",
    "        )\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Usage Example:\n",
    "# Assuming df is your DataFrame, and you want to split it.\n",
    "# df = pd.read_csv('your_data.csv')  # Load your DataFrame\n",
    "feature_columns = [f'feature_{i}' for i in range(20)]  # Adjust as per your feature column names\n",
    "target_column = 'pain_level'\n",
    "subject_column = 'subject'\n",
    "window_length = 50  # Sequence length\n",
    "step_size = 25      # Step size\n",
    "\n",
    "datasets = prepare_sliding_window_dataset(df, feature_columns, target_column, subject_column, window_length, step_size)\n",
    "\n",
    "# Get the dataset for a specific subject\n",
    "leave_out_subject = 'Subject_1'  # Example subject\n",
    "dataset = datasets[leave_out_subject]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "test_features, test_targets = dataset.get_test_data()\n",
    "\n",
    "# Example: Iterate through train data\n",
    "for batch_features, batch_targets in train_loader:\n",
    "    print(batch_features.shape, batch_targets.shape)\n",
    "\n",
    "# Example: Access test data\n",
    "print(test_features.shape, test_targets.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
