{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from utils.EmoPainDataset import KinematicsDataset, SlidingWindowDataset, create_weighted_sampler\n",
    "from utils.models import KinematicsTransformer, KinematicsLSTM, FocalLoss\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from utils.training import train_transformer, pretrain_transformer\n",
    "\n",
    "filepath='EmoPainData/P.feather'\n",
    "\n",
    "sampling_frequency = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe\n",
    "df=pd.read_feather(filepath)\n",
    "#df=pd.concat([pd.read_feather('EmoPainData/P.feather'), pd.read_feather('EmoPainData/C.feather')], axis=0, ignore_index=True)\n",
    "df.columns = [feature[:-4] if (feature.find('nan')!=-1) else feature for feature in df.columns] # drop 'nan' in column names\n",
    "# calculate a soft probability of protective behaviors\n",
    "behavior_ratings=[feature for feature in df.columns if feature.find('Rater')!=-1]\n",
    "df.insert(df.shape[-1], 'behavior prob', (df[behavior_ratings]/2).mean(axis=1)) # divided by 2 because the max label is 2\n",
    "# calculate a binary label of protective behaviors based on the majority voting used in the original paper and Wang et. al \n",
    "binary_labels_per_rater, PB_label=pd.DataFrame(), pd.DataFrame()\n",
    "for rater_num in range(1,5):    # loop through all 4 raters\n",
    "    behavior_ratings=[feature for feature in df.columns if feature.find('Rater '+str(rater_num))!=-1]\n",
    "    # the maximum label of each frame given by each rater\n",
    "    pb = df[behavior_ratings].max(axis=1)\n",
    "    PB_label.insert(rater_num-1,str(rater_num), pb)\n",
    "    # create a binary label based on majority voting of all 4 raters\n",
    "    binary_label = ((df[behavior_ratings]==1) | (df[behavior_ratings]==2)).max(axis=1)\n",
    "    binary_labels_per_rater.insert(rater_num-1,str(rater_num), binary_label)\n",
    "majority_voting_binary_label = (binary_labels_per_rater.sum(axis=1)>=2).astype(int)\n",
    "df.insert(df.shape[-1], 'behavior binary', majority_voting_binary_label)\n",
    "df.insert(df.shape[-1], 'PB prob', PB_label.mean(axis=1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hip' 'LeftUpperLeg' 'LeftLowerLeg' 'LeftAnkle' 'LeftHeel' 'LeftToes'\n",
      " 'RightUpperLeg' 'RightLowerLeg' 'RightAnkle' 'RightHeel' 'RightToes'\n",
      " 'Spine' 'Spine 1' 'LeftShoulder' 'LeftUpperArm' 'LeftLowerArm'\n",
      " 'LeftWrist' 'LeftFingertip' 'RightShoulder' 'RightUpperArm' 'RightArm'\n",
      " 'RightWrist' 'RightFingertip' 'Neck' 'Head' 'Crown'\n",
      " 'Rectified EMG Probe 1:Right Lower' 'Rectified EMG Probe 2:Left Lower'\n",
      " 'Rectified EMG Probe 3:Right Upper' 'Recfified EMG Probe 4:Left Upper'\n",
      " 'Rater 1- Guarding/Stiffness' 'Rater 1- Hesitation'\n",
      " 'Rater 1- Support/Bracing' 'Rater 1- Jerky Motion' 'Rater 1 - Limping'\n",
      " 'Rater 1 - Rubbing/Stimulation' 'Rater 1 - Other'\n",
      " 'Rater 2- Guarding/Stiffness' 'Rater 2- Hesitation'\n",
      " 'Rater 2- Support/Bracing' 'Rater 2- Jerky Motion' 'Rater 2 - Limping'\n",
      " 'Rater 2 - Rubbing/Stimulation' 'Rater 2 - Other'\n",
      " 'Rater 3- Guarding/Stiffness' 'Rater 3- Hesitation'\n",
      " 'Rater 3- Support/Bracing' 'Rater 3- Jerky Motion' 'Rater 3 - Limping'\n",
      " 'Rater 3 - Rubbing/Stimulation' 'Rater 3 - Other'\n",
      " 'Rater 4- Guarding/Stiffness' 'Rater 4- Hesitation'\n",
      " 'Rater 4- Support/Bracing' 'Rater 4- Jerky Motion' 'Rater 4 - Limping'\n",
      " 'Rater 4 - Rubbing/Stimulation' 'Rater 4 - Other' 'One Leg Stand 1'\n",
      " 'One Leg Stand 2' 'One Leg Stand 3' 'One Leg Stand 4' 'One Leg Stand 5'\n",
      " 'One Leg Stand 6' 'Sitting Still' 'Reach Forward 2' 'Reach Forward 1'\n",
      " 'Sit to Stand Instructed 1' 'Sit to Stand Instructed 2'\n",
      " 'Sit to Stand Instructed 3' 'Stand to Sit Instructed 1'\n",
      " 'Stand to Sit Instructed 2' 'Stand to Sit Instructed 3' 'Standing Still'\n",
      " 'Sit to Stand Not Instructed' 'Stand to Sit Not Instructed' 'Bend 2'\n",
      " 'Bend 1' 'Walk' 'Other Major: Bend to pick up'\n",
      " 'Sit to Stand Instructed 4' 'Stand to Sit Instructed 4'\n",
      " 'Joint Angle:Crown-Hip-LeftFoot' 'Joint Angle:Crown-Hip-RightFoot'\n",
      " 'Joint Angle:Spine-Hip-LeftLeg' 'Joint Angle:Spine-Hip-RightLeg'\n",
      " 'Joint Angle:Left-Knee' 'Joint Angle:Right-Knee' 'Joint Angle:Left-Elbow'\n",
      " 'Joint Angle:Right-Elbow' 'Joint Angle:Left-Shoulder'\n",
      " 'Joint Angle:Right-Shoulder'\n",
      " 'Joint Angle:LeftShoulder-LeftUpperLeg-LeftLowerLeg'\n",
      " 'Joint Angle:RightShoulder-RightUpperLeg-RightLowerLeg'\n",
      " 'Joint Angle:Neck' 'Joint Energy:Crown-Hip-LeftFoot'\n",
      " 'Joint Energy:Crown-Hip-RightFoot' 'Joint Energy:Spine-Hip-LeftLeg'\n",
      " 'Joint Energy:Spine-Hip-RightLeg' 'Joint Energy:Left-Knee'\n",
      " 'Joint Energy:Right-Knee' 'Joint Energy:Left-Elbow'\n",
      " 'Joint Energy:Right-Elbow' 'Joint Energy:Left-Shoulder'\n",
      " 'Joint Energy:Right-Shoulder'\n",
      " 'Joint Energy:LeftShoulder-LeftUpperLeg-LeftLowerLeg'\n",
      " 'Joint Energy:RightShoulder-RightUpperLeg-RightLowerLeg'\n",
      " 'Joint Energy:Neck' 'Subject' 'Difficulty' 'behavior prob'\n",
      " 'behavior binary' 'PB prob']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(473210, 113)\n",
      "Rater 1- Guarding/Stiffness      0.962782\n",
      "Rater 1- Hesitation              0.997483\n",
      "Rater 1- Support/Bracing         0.991701\n",
      "Rater 1- Jerky Motion            0.992327\n",
      "Rater 1 - Limping                0.992158\n",
      "Rater 1 - Rubbing/Stimulation    0.997969\n",
      "Rater 1 - Other                  0.998599\n",
      "Rater 2- Guarding/Stiffness      0.782498\n",
      "Rater 2- Hesitation              0.997099\n",
      "Rater 2- Support/Bracing         0.963226\n",
      "Rater 2- Jerky Motion            0.952554\n",
      "Rater 2 - Limping                0.948040\n",
      "Rater 2 - Rubbing/Stimulation    0.987834\n",
      "Rater 2 - Other                  1.000000\n",
      "Rater 3- Guarding/Stiffness      0.903559\n",
      "Rater 3- Hesitation              0.998614\n",
      "Rater 3- Support/Bracing         0.970436\n",
      "Rater 3- Jerky Motion            0.984527\n",
      "Rater 3 - Limping                0.981625\n",
      "Rater 3 - Rubbing/Stimulation    0.997394\n",
      "Rater 3 - Other                  0.997416\n",
      "Rater 4- Guarding/Stiffness      0.708066\n",
      "Rater 4- Hesitation              0.989816\n",
      "Rater 4- Support/Bracing         0.967902\n",
      "Rater 4- Jerky Motion            0.997234\n",
      "Rater 4 - Limping                0.971700\n",
      "Rater 4 - Rubbing/Stimulation    0.995211\n",
      "Rater 4 - Other                  0.984859\n",
      "dtype: float64\n",
      "Rater 1- Guarding/Stiffness      0.959502\n",
      "Rater 1- Hesitation              0.858034\n",
      "Rater 1- Support/Bracing         1.003571\n",
      "Rater 1- Jerky Motion            0.586282\n",
      "Rater 1 - Limping                0.945988\n",
      "Rater 1 - Rubbing/Stimulation    1.483204\n",
      "Rater 1 - Other                  0.831492\n",
      "Rater 2- Guarding/Stiffness      0.003353\n",
      "Rater 2- Hesitation              0.000000\n",
      "Rater 2- Support/Bracing         0.000000\n",
      "Rater 2- Jerky Motion            0.005103\n",
      "Rater 2 - Limping                0.000000\n",
      "Rater 2 - Rubbing/Stimulation    0.006469\n",
      "Rater 2 - Other                       NaN\n",
      "Rater 3- Guarding/Stiffness      2.453947\n",
      "Rater 3- Hesitation              0.477477\n",
      "Rater 3- Support/Bracing         2.602884\n",
      "Rater 3- Jerky Motion            0.068281\n",
      "Rater 3 - Limping                     inf\n",
      "Rater 3 - Rubbing/Stimulation         inf\n",
      "Rater 3 - Other                       inf\n",
      "Rater 4- Guarding/Stiffness      1.154928\n",
      "Rater 4- Hesitation              1.062928\n",
      "Rater 4- Support/Bracing         0.825601\n",
      "Rater 4- Jerky Motion            2.016129\n",
      "Rater 4 - Limping                0.136746\n",
      "Rater 4 - Rubbing/Stimulation    6.170886\n",
      "Rater 4 - Other                  3.172976\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "behavior_ratings=[feature for feature in df.columns if feature.find('Rater')!=-1]\n",
    "print(df.shape)\n",
    "print((df[behavior_ratings]==0).sum(axis=0)/df.shape[0])\n",
    "print((df[behavior_ratings]==1).sum(axis=0)/(df[behavior_ratings]==2).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([660, 180, 26]) torch.Size([660, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.EmoPainDataset import KinematicsDataset, SlidingWindowDataset\n",
    "\n",
    "# Load the dataset\n",
    "    # indicate which features to use\n",
    "subjects = df.Subject.unique()\n",
    "leave_out_subject = subjects[0]\n",
    "kinematic_features=[feature for feature in df.columns if feature.find('Energy')!=-1 or feature.find('Angle')!=-1 ]\n",
    "behavior_ratings=[feature for feature in df.columns if feature.find('Rater')!=-1]\n",
    "PB_prob='PB prob'\n",
    "behavior_prob='behavior prob'\n",
    "behavior_binary='behavior binary'\n",
    "target_features = [behavior_binary] # target\n",
    "df = df.dropna(subset=kinematic_features,)  # the first sample for each subject is nan for energy features; so drop them\n",
    "#\n",
    "window_size, step_size = int(sampling_frequency*3), int(sampling_frequency*0.75)  # experiment parameters\n",
    "\n",
    "dataset = SlidingWindowDataset(df, leave_out_subject, kinematic_features, target_features, 'Subject', window_size, step_size)\n",
    "test_features, test_targets = dataset.get_test_data()\n",
    "print(test_features.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   1. majority voting of maximum labels (the label of a frame from a single rater is the max label they give across all 7 PBs)\n",
    "    #   a. per-frame prediction\n",
    "    #   b. per-sequence prediction (majority voting of frames)\n",
    "\n",
    "#   2. mean scores as labels across all raters and all categories, divided by 2\n",
    "    #   a. per-frame prediction\n",
    "    #   b. per-sequence prediction (mean of frames)\n",
    "\n",
    "\n",
    "\n",
    "#   Pre-training schemes\n",
    "    #   1. Transformer\n",
    "        #   a. Train the encoder and decoder to predict the activity at each frame\n",
    "        #   b. Train the encoder and decoder to \n",
    "        #   c. Evaluate the pre-trained model on the test set\n",
    "    #   2.  LSTM\n",
    "    #   3.  Point-Net\n",
    "\n",
    "\n",
    "#   Fine-tuning schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(df[kinematic_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.7071],\n",
       "         [ 0.5950,  0.3821],\n",
       "         [ 0.6430, -0.2943],\n",
       "         [ 0.0998, -0.7000],\n",
       "         [-0.5351, -0.4622],\n",
       "         [-0.6781,  0.2006],\n",
       "         [-0.1976,  0.6789],\n",
       "         [ 0.4646,  0.5331],\n",
       "         [ 0.6996, -0.1029],\n",
       "         [ 0.2914, -0.6443]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.models import SinusoidalPositionalEncoding\n",
    "\n",
    "PE = SinusoidalPositionalEncoding(2)\n",
    "PE.forward(torch.zeros(1, 10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = test_features.shape[-1]           # Number of features in each kinematics sample\n",
    "num_classes = 2\n",
    "seq_len = window_size       # Sequence length (window length)\n",
    "embed_dim = 256             # Embedding dimension\n",
    "num_heads = 4               # Number of attention heads\n",
    "num_layers = 4              # Number of transformer layers\n",
    "dropout = 0.1               # Dropout rate\n",
    "lr = 1e-2                   # Learning rate\n",
    "masking_prob = 0.2          # Probability of masking each feature\n",
    "pretrain_epochs = 10        # Pretraining epochs\n",
    "fine_tune_epochs = 10       # Fine-tuning epochs\n",
    "batch_size = 64             # Batch size\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Initialize model\n",
    "model = KinematicsTransformer(input_dim, num_classes, seq_len, embed_dim, num_heads, num_layers, dropout)\n",
    "#model = KinematicsLSTM(input_dim, embed_dim, num_classes, num_layers, dropout, bidirectional=True)\n",
    "torch.cuda.empty_cache()\n",
    "# Create a weighted sampler\n",
    "weighted_sampler = create_weighted_sampler(dataset, num_bins=2)\n",
    "\n",
    "# DataLoader with weighted sampling\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=weighted_sampler)\n",
    "test_features, test_targets = dataset.get_test_data()\n",
    "val_loader = DataLoader(TensorDataset(test_features, test_targets), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 1/10, Loss: 1.2649\n",
      "Pretraining Epoch 2/10, Loss: 1.3565\n",
      "Pretraining Epoch 3/10, Loss: 1.4396\n",
      "Pretraining Epoch 4/10, Loss: 1.2030\n",
      "Pretraining Epoch 5/10, Loss: 1.3619\n",
      "Pretraining Epoch 6/10, Loss: 1.3794\n",
      "Pretraining Epoch 7/10, Loss: 1.3489\n",
      "Pretraining Epoch 8/10, Loss: 1.4754\n",
      "Pretraining Epoch 9/10, Loss: 1.2972\n",
      "Pretraining Epoch 10/10, Loss: 1.3598\n"
     ]
    }
   ],
   "source": [
    "# Pretrain the transformer\n",
    "torch.cuda.empty_cache()\n",
    "pretrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "pretrain_loader = train_loader\n",
    "model.pretrain=True\n",
    "pretrain_transformer(model, pretrain_loader, pretrain_epochs, lr, masking_prob, device, parameters=model.backbone.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6759, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 2/10, Train Loss: 0.6751, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 3/10, Train Loss: 0.6758, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 4/10, Train Loss: 0.6758, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 5/10, Train Loss: 0.6758, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 6/10, Train Loss: 0.6747, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 7/10, Train Loss: 0.6749, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 8/10, Train Loss: 0.6759, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 9/10, Train Loss: 0.6754, Val Loss: 0.6758, Val Accuracy: 0.6628\n",
      "Epoch 10/10, Train Loss: 0.6753, Val Loss: 0.6758, Val Accuracy: 0.6628\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "model.pretrain=False\n",
    "train_transformer(model, train_loader, val_loader, fine_tune_epochs, lr, device,parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "#test_targets=test_targets.to(device)\n",
    "predictions=model(test_features.to(device))\n",
    "#balanced_accuracy_score(test_targets.mean(dim=-2) > 0.5, predictions.mean(dim=-2).cpu().detach() > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y =[], []\n",
    "for x,y in train_loader:\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "X = torch.cat(X)\n",
    "Y = torch.cat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2430)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y == 1).sum()/Y.flatten().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4500],\n",
       "        [0.9000],\n",
       "        [0.6556],\n",
       "        ...,\n",
       "        [0.0000],\n",
       "        [1.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mean(dim=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dataset.get_train_data()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(torch.max(y, dim=1)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
